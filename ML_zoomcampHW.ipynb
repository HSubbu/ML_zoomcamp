{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_zoomcampHW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trh-Vxm_PGrH"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "In this homework, we'll build a model for predicting if we have an image of a dog or a cat. For this, we will use the \"Dogs & Cats\" dataset that can be downloaded from Kaggle.\n",
        "\n",
        "You need to download the train.zip file.\n",
        "\n",
        "If you have troubles downloading from Kaggle, use this link instead:\n",
        "\n",
        "wget https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip\n",
        "\n",
        "In the lectures we saw how to use a pre-trained neural network. In the homework, we'll train a much smaller model from scratch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHd-15wPuwPM"
      },
      "source": [
        "! rm -rf train.zip "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIe8xFjDvJke"
      },
      "source": [
        "! rm -rf train/"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4f2mpK8udlk"
      },
      "source": [
        "!rm -rf /content/train_data"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkOi8iZJuj5v"
      },
      "source": [
        "!rm -rf /content/val_data"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ6t3cbJurno",
        "outputId": "3d0a40b2-b5be-4f7d-fe83-02f80ca784f4"
      },
      "source": [
        "ls "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rzVB5t5POKG",
        "outputId": "9f8e3a1e-979d-4fea-c2e2-e72839caae1e"
      },
      "source": [
        "!wget https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-20 00:26:53--  https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip\n",
            "Resolving github.com (github.com)... 13.114.40.48\n",
            "Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/426348925/f39169c9-5f22-4a57-bb37-495c0d2974ab?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211120T002653Z&X-Amz-Expires=300&X-Amz-Signature=ad6bcad4f7db44b0ee2d75eb8f650946760c9e8044a86eb41295c35fd618eafd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=426348925&response-content-disposition=attachment%3B%20filename%3Dtrain.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-11-20 00:26:53--  https://github-releases.githubusercontent.com/426348925/f39169c9-5f22-4a57-bb37-495c0d2974ab?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211120T002653Z&X-Amz-Expires=300&X-Amz-Signature=ad6bcad4f7db44b0ee2d75eb8f650946760c9e8044a86eb41295c35fd618eafd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=426348925&response-content-disposition=attachment%3B%20filename%3Dtrain.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.111.154, 185.199.110.154, 185.199.108.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.111.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 569546721 (543M) [application/octet-stream]\n",
            "Saving to: ‘train.zip’\n",
            "\n",
            "train.zip           100%[===================>] 543.16M  27.3MB/s    in 21s     \n",
            "\n",
            "2021-11-20 00:27:14 (26.0 MB/s) - ‘train.zip’ saved [569546721/569546721]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsPH3F3KP4qo"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "The dataset contains 12,500 images of cats and 12,500 images of dogs.\n",
        "\n",
        "Now we need to split this data into train and validation\n",
        "\n",
        "Create a train and validation folders\n",
        "\n",
        "In each folder, create cats and dogs folders\n",
        "Move the first 10,000 images to the train folder (from 0 to 9999) for boths cats and dogs - and put them in respective folders\n",
        "\n",
        "Move the remaining 2,500 images to the validation folder (from 10000 to 12499)\n",
        "You can do this manually or with Python (check os and shutil packages)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDU-MuATPTDj"
      },
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"train.zip\",\"/content/\") #unzip train.zip"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYIIkmZGSm6n",
        "outputId": "217c9da1-0ca8-4971-cd45-20d492ebfee4"
      },
      "source": [
        "# check directory content\n",
        "!ls -l  train/ | wc -l"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU1snebFT2XI",
        "outputId": "93ef8d11-d897-4ba9-e241-68780ed2eb31"
      },
      "source": [
        "! ls train/ | grep \"dog\" | wc -l"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvKf431JU0KQ",
        "outputId": "7d4e940d-f53b-4494-ddbd-b4d917023ce9"
      },
      "source": [
        "! ls train/ | grep \"cat\" | wc -l"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0tWcUYLV7vQ"
      },
      "source": [
        "#create two folders train_data and val_data\n",
        "import shutil, os\n",
        "# Parent Directory path\n",
        "parent_dir = \"/content/\"\n",
        "folders = ['train_data','val_data']\n",
        "for folder in folders:\n",
        "  path = parent_dir+folder\n",
        "  os.mkdir(path)\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gETGHAKatcX"
      },
      "source": [
        "folders = ['/content/train_data/','/content/val_data/']\n",
        "sub_folders = ['cats','dogs']\n",
        "for folder in folders:\n",
        "  for subfolder in sub_folders:\n",
        "    path = folder+subfolder\n",
        "    os.mkdir(path)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltoFwZ2gcRnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0352989a-3128-497b-ef6a-0f93f6e37bd6"
      },
      "source": [
        "!ls train_data/"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cats  dogs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmkGUTwRY81Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "813ff036-3f3e-4145-87d4-3a1f510baaeb"
      },
      "source": [
        "!ls val_data/"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cats  dogs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4iUPX6lZ5BS"
      },
      "source": [
        "source_dir = \"/content/train\"\n",
        "   \n",
        "file_names = os.listdir(source_dir)\n",
        "\n",
        "cat_count=0\n",
        "dog_count=0\n",
        "\n",
        "for file_name in file_names:\n",
        "    \n",
        "      if \"cat\" in file_name:\n",
        "          cat_count+=1\n",
        "          if (cat_count <= 10000):\n",
        "             target_dir = '/content/train_data/cats'\n",
        "             shutil.move(os.path.join(source_dir, file_name), target_dir)\n",
        "          else:\n",
        "             target_dir = '/content/val_data/cats'\n",
        "             shutil.move(os.path.join(source_dir, file_name), target_dir)\n",
        "\n",
        "      elif \"dog\" in file_name:\n",
        "          dog_count+=1\n",
        "          if (dog_count <= 10000):\n",
        "            target_dir = '/content/train_data/dogs'\n",
        "            shutil.move(os.path.join(source_dir, file_name), target_dir)\n",
        "          else:\n",
        "            target_dir = '/content/val_data/dogs'\n",
        "            shutil.move(os.path.join(source_dir, file_name), target_dir)\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zamanL0UdD2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a9d627-bc89-4abe-d5e8-ccfd33ff7974"
      },
      "source": [
        "!ls train_data/cats | wc -l"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crq-XYBCdG26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "262b0571-197e-4fbd-b9c4-d8414525f2a0"
      },
      "source": [
        "!ls train_data/dogs | wc -l"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpUsxvIjdUHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b3e5f8-1f10-481c-c072-41b7ab304be7"
      },
      "source": [
        "!ls val_data/cats | wc -l"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdN482BndXD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce758e1e-5c7d-4945-fe33-fd1b37e8e0e1"
      },
      "source": [
        "!ls val_data/dogs | wc -l"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH7I2ciWpj-2"
      },
      "source": [
        "Now we have 10000 images of cats and dogs in train_data and 2500 each of dogs and cats in val_data as a part of data preparation process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmTjE0uxqJX0"
      },
      "source": [
        "## Model\n",
        "\n",
        "For this homework we will use Convolutional Neural Network (CNN. Like in the lectures, we'll use Keras.\n",
        "\n",
        "You need to develop the model with following structure:\n",
        "\n",
        "The shape for input should be (150, 150, 3)\n",
        "Next, create a covolutional layer (Conv2D):\n",
        "Use 32 filters\n",
        "Kernel size should be (3, 3) (that's the size of the filter)\n",
        "Use 'relu' as activation\n",
        "Reduce the size of the feature map with max pooling (MaxPooling2D)\n",
        "Set the pooling size to (2, 2)\n",
        "Turn the multi-dimensional result into vectors using a Flatten layer\n",
        "Next, add a Dense layer with 64 neurons and 'relu' activation\n",
        "Finally, create the Dense layer with 1 neuron - this will be the output\n",
        "The output layer should have an activation - use the appropriate activation for the binary classification case\n",
        "As optimizer use SGD with the following parameters:\n",
        "\n",
        "SGD(lr=0.002, momentum=0.8)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb8Pkml2hsRK"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhUd4dAbfHH_"
      },
      "source": [
        "We’ll first add a convolutional 2D layer with 32 filters, a kernel of 3x3, the input size as our image dimensions, 150x150x3, and the activation as ReLU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6N9BRi1fX_I"
      },
      "source": [
        "add a max pooling layer that halves the image dimension, so after this layer, the output will be 75x75x3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDzardozfnFc"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "# Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "# This is the first convolution\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "# Flatten the results to feed into a DNN\n",
        "      tf.keras.layers.Flatten(),\n",
        "# 64 neuron hidden layer\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "# Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cat') and 1 for the other ('dog')\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbbJebTogrLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095cd1b3-4576-4a81-e091-0ae8f7f0550e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 175232)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                11214912  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,215,873\n",
            "Trainable params: 11,215,873\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j66Z4tuih6AU"
      },
      "source": [
        "Question 1\n",
        "Since we have a binary classification problem, what is the best loss function for us?\n",
        "\n",
        "Note: since we specify an activation for the output layer, we don't need to set from_logits=True\n",
        "\n",
        "Ans **binary_crossentropy**\n",
        "\n",
        "Question 2\n",
        "\n",
        "\n",
        "What's the total number of parameters of the model? You can use the summary method for that.\n",
        "\n",
        "Ans **11,215,873**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxHTHiJjhsvL"
      },
      "source": [
        "optimizer = tf.keras.optimizers.SGD(\n",
        "                                    learning_rate=0.002, momentum=0.8)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfFx4UBHi3cz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8dc28b6-3507-4f94-d065-195321b73c0d"
      },
      "source": [
        "train_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_ds = train_gen.flow_from_directory(\n",
        "                       '/content/train_data',\n",
        "                        target_size=(150, 150),\n",
        "                        batch_size=20,\n",
        "                        class_mode = 'binary'\n",
        ")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x_uD_Rwj--6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e549d08-d429-422e-b6e2-373137f52052"
      },
      "source": [
        "train_ds.class_indices"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cats': 0, 'dogs': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAOvSt_ekFYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ee5e18-2186-4f36-a636-f6a6c9fc03f9"
      },
      "source": [
        "val_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_ds = val_gen.flow_from_directory(\n",
        "              '/content/val_data',\n",
        "              target_size=(150, 150),\n",
        "              batch_size=20,\n",
        "              class_mode = 'binary'\n",
        ")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukhKwkxDkvUE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd8dc0e9-c1aa-4d4f-a3bf-32c59786d69b"
      },
      "source": [
        "train_ds.class_mode"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'binary'"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjiqBTP7kysA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e620f4-2ded-4179-a9bb-0c65a8be6761"
      },
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=50\n",
        ")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 12s 106ms/step - loss: 0.6981 - accuracy: 0.5265 - val_loss: 0.6923 - val_accuracy: 0.4980\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.6924 - accuracy: 0.5365 - val_loss: 0.6842 - val_accuracy: 0.5560\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.6750 - accuracy: 0.5745 - val_loss: 0.6660 - val_accuracy: 0.5880\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.6712 - accuracy: 0.5745 - val_loss: 0.6882 - val_accuracy: 0.5630\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.6634 - accuracy: 0.5900 - val_loss: 0.6632 - val_accuracy: 0.5840\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.6462 - accuracy: 0.6225 - val_loss: 0.6440 - val_accuracy: 0.6260\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.6491 - accuracy: 0.6080 - val_loss: 0.6492 - val_accuracy: 0.6290\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.6470 - accuracy: 0.6090 - val_loss: 0.6329 - val_accuracy: 0.6630\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.6348 - accuracy: 0.6390 - val_loss: 0.6480 - val_accuracy: 0.6000\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.6209 - accuracy: 0.6520 - val_loss: 0.6529 - val_accuracy: 0.6130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffVraE54xxkk"
      },
      "source": [
        "Question 3\n",
        "\n",
        "What is the median of training accuracy for this model?\n",
        "\n",
        "Question 4\n",
        "\n",
        "What is the standard deviation of training loss for this model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl3VUN7nm5cB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89941216-d80c-4c3a-b0bf-ce9c7b0739d2"
      },
      "source": [
        "history.history.keys()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-d2a3Q8osv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59936b49-dbe9-43ec-9789-9134ada39e50"
      },
      "source": [
        "np.median(history.history['accuracy'])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5989999771118164"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7Co0p-fozgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b5a01e7-8beb-4685-82f3-db9ed1c8102b"
      },
      "source": [
        "np.std(history.history['loss'])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02347979842346073"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcI2REGgqEQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cca686c-aa5a-4cab-8c51-3a1c2ee02d3f"
      },
      "source": [
        "train_gen = ImageDataGenerator(rescale=1./255,\n",
        "                               rotation_range=40,\n",
        "                                width_shift_range=0.2,\n",
        "                                height_shift_range=0.2,\n",
        "                                shear_range=0.2,\n",
        "                                zoom_range=0.2,\n",
        "                                horizontal_flip=True,\n",
        "                                fill_mode='nearest')\n",
        "\n",
        "train_ds = train_gen.flow_from_directory(\n",
        "                       '/content/train_data',\n",
        "                        target_size=(150, 150),\n",
        "                        batch_size=20\n",
        ")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVFaBzG0qzSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a83698-7c1e-461e-f269-94d4ef5394a0"
      },
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=50\n",
        ")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 21s 204ms/step - loss: 0.7043 - accuracy: 0.5000 - val_loss: 0.6625 - val_accuracy: 0.6640\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 20s 201ms/step - loss: 0.6950 - accuracy: 0.5000 - val_loss: 0.6727 - val_accuracy: 0.6560\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.6787 - val_accuracy: 0.6150\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 20s 201ms/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6820 - val_accuracy: 0.6170\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6858 - val_accuracy: 0.6070\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6859 - val_accuracy: 0.6090\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 20s 203ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6862 - val_accuracy: 0.6180\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 20s 203ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6872 - val_accuracy: 0.6230\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6863 - val_accuracy: 0.5970\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6872 - val_accuracy: 0.6290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7I0LYJxDkH"
      },
      "source": [
        "Question 5\n",
        "\n",
        "Let's train our model for 10 more epochs using the same code as previously. Make sure you don't re-create the model - we want to continue training the model we already started training.\n",
        "\n",
        "What is the mean of validation loss for the model trained with augmentations?\n",
        "\n",
        "\n",
        "\n",
        "Question 6\n",
        "\n",
        "\n",
        "What's the average of validation accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOyUOGv4q-IZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bfaed70-576a-4a41-f1fc-ac79178a54e2"
      },
      "source": [
        "np.mean(history.history['val_loss'])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6814465641975402"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euplAFE0xRzD",
        "outputId": "4cb6340d-774a-41dc-bebf-cd351d6b4466"
      },
      "source": [
        "np.mean(history.history['val_accuracy'][5:])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6152000069618225"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REyL0rgzxbHu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}